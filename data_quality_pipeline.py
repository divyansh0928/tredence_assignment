import asyncio
import aiohttp
import json
import random
import statistics
import time
from typing import Dict, Any, List
from datetime import datetime, timedelta
import copy

def generate_sample_dataset(size: int = 1000) -> List[Dict[str, Any]]:
    random.seed(42)
    
    data = []
    for i in range(size):
        record = {
            'id': i + 1,
            'name': generate_name(),
            'email': generate_email(i),
            'age': generate_age(),
            'salary': generate_salary(),
            'department': generate_department(),
            'join_date': generate_date(),
            'score': generate_score(),
        }
        data.append(record)
    
    return data

def generate_name():
    names = ['John Smith', 'Jane Doe', 'Bob Johnson', 'Alice Brown', 'Charlie Wilson']
    
    if random.random() < 0.05:
        return None
    elif random.random() < 0.03:  
        return ""
    elif random.random() < 0.02: 
        return "123Invalid"
    else:
        return random.choice(names)

def generate_email(id_num):
    domains = ['gmail.com', 'yahoo.com', 'company.com', 'outlook.com']
    
    if random.random() < 0.04:  
        return f"invalid_email_{id_num}"
    elif random.random() < 0.02:
        return None
    else:
        return f"user{id_num}@{random.choice(domains)}"

def generate_age():
    if random.random() < 0.03:
        return random.choice([-5, 150, 999])
    elif random.random() < 0.02:
        return None
    else:
        return random.randint(22, 65)

def generate_salary():
    if random.random() < 0.02:
        return random.choice([1, 10000000])
    elif random.random() < 0.01:
        return None
    else:
        return random.randint(30000, 150000)

def generate_department():
    departments = ['Engineering', 'Sales', 'Marketing', 'HR', 'Finance']
    
    if random.random() < 0.03:
        return random.choice(['Eng', 'engineering', 'SALES', 'mktg'])
    elif random.random() < 0.01:
        return None
    else:
        return random.choice(departments)

def generate_date():
    if random.random() < 0.02:
        return (datetime.now() + timedelta(days=random.randint(1, 365))).isoformat()
    elif random.random() < 0.01:
        return None
    else:
        start_date = datetime(2020, 1, 1)
        end_date = datetime.now()
        random_date = start_date + timedelta(
            days=random.randint(0, (end_date - start_date).days)
        )
        return random_date.isoformat()

def generate_score():
    if random.random() < 0.02:
        return random.choice([-10, 150])
    elif random.random() < 0.01:
        return None
    else:
        return round(random.uniform(0, 100), 2)


async def initialize_dataset(state: Dict[str, Any]) -> Dict[str, Any]:
    print("ğŸ”„ Initializing dataset...")
    await asyncio.sleep(1)
    
    dataset_size = state.get('dataset_size', 1000)
    dataset = generate_sample_dataset(dataset_size)
    
    state.update({
        'dataset': dataset,
        'original_size': len(dataset),
        'iteration': 0,
        'max_iterations': state.get('max_iterations', 5),
        'target_anomaly_rate': state.get('target_anomaly_rate', 0.05),
        'pipeline_start_time': datetime.now().isoformat(),
        'quality_history': []
    })
    
    print(f"âœ… Dataset initialized with {len(dataset)} records")
    return state

async def profile_data(state: Dict[str, Any]) -> Dict[str, Any]:
    print("ğŸ“Š Profiling data...")
    await asyncio.sleep(2)
    
    dataset = state['dataset']
    state['iteration'] += 1
    
    profile = {
        'total_records': len(dataset),
        'columns': {},
        'completeness': {},
        'statistics': {}
    }
    
    for column in ['name', 'email', 'age', 'salary', 'department', 'join_date', 'score']:
        values = [record.get(column) for record in dataset]
        non_null_values = [v for v in values if v is not None and v != ""]
        
        profile['columns'][column] = {
            'total_count': len(values),
            'non_null_count': len(non_null_values),
            'null_count': len(values) - len(non_null_values),
            'null_percentage': (len(values) - len(non_null_values)) / len(values) * 100
        }
        
        profile['completeness'][column] = len(non_null_values) / len(values)
        
        if column in ['age', 'salary', 'score']:
            numeric_values = [v for v in non_null_values if isinstance(v, (int, float))]
            if numeric_values:
                profile['statistics'][column] = {
                    'mean': statistics.mean(numeric_values),
                    'median': statistics.median(numeric_values),
                    'min': min(numeric_values),
                    'max': max(numeric_values),
                    'std_dev': statistics.stdev(numeric_values) if len(numeric_values) > 1 else 0
                }
    
    state['data_profile'] = profile
    
    print(f"âœ… Data profiling completed for iteration {state['iteration']}")
    print(f"   - Total records: {profile['total_records']}")
    print(f"   - Average completeness: {sum(profile['completeness'].values()) / len(profile['completeness']):.2%}")
    
    return state

async def identify_anomalies(state: Dict[str, Any]) -> Dict[str, Any]:
    print("ğŸ” Identifying anomalies...")
    await asyncio.sleep(1.5)
    
    dataset = state['dataset']
    anomalies = {
        'null_values': [],
        'invalid_emails': [],
        'age_outliers': [],
        'salary_outliers': [],
        'future_dates': [],
        'score_outliers': [],
        'department_inconsistencies': []
    }
    
    for i, record in enumerate(dataset):
        record_id = record.get('id', i)
        
        for field in ['name', 'email', 'age', 'salary', 'department']:
            if record.get(field) is None or record.get(field) == "":
                anomalies['null_values'].append({
                    'record_id': record_id,
                    'field': field,
                    'issue': 'null_or_empty'
                })
        
        # Check email format
        email = record.get('email')
        if email and '@' not in str(email):
            anomalies['invalid_emails'].append({
                'record_id': record_id,
                'value': email,
                'issue': 'invalid_format'
            })
        
        # Check age outliers
        age = record.get('age')
        if isinstance(age, (int, float)) and (age < 18 or age > 70):
            anomalies['age_outliers'].append({
                'record_id': record_id,
                'value': age,
                'issue': 'age_outlier'
            })
        
        # Check salary outliers
        salary = record.get('salary')
        if isinstance(salary, (int, float)) and (salary < 20000 or salary > 500000):
            anomalies['salary_outliers'].append({
                'record_id': record_id,
                'value': salary,
                'issue': 'salary_outlier'
            })
        
        # Check future join dates
        join_date = record.get('join_date')
        if join_date:
            try:
                date_obj = datetime.fromisoformat(join_date.replace('Z', '+00:00'))
                if date_obj > datetime.now():
                    anomalies['future_dates'].append({
                        'record_id': record_id,
                        'value': join_date,
                        'issue': 'future_date'
                    })
            except:
                pass
        
        # Check score outliers
        score = record.get('score')
        if isinstance(score, (int, float)) and (score < 0 or score > 100):
            anomalies['score_outliers'].append({
                'record_id': record_id,
                'value': score,
                'issue': 'score_out_of_range'
            })
        
        # Check department inconsistencies
        department = record.get('department')
        if department and department not in ['Engineering', 'Sales', 'Marketing', 'HR', 'Finance']:
            anomalies['department_inconsistencies'].append({
                'record_id': record_id,
                'value': department,
                'issue': 'inconsistent_naming'
            })
    
    # Calculate total anomaly count and rate
    total_anomalies = sum(len(anomaly_list) for anomaly_list in anomalies.values())
    anomaly_rate = total_anomalies / len(dataset)
    
    state['anomalies'] = anomalies
    state['total_anomalies'] = total_anomalies
    state['anomaly_rate'] = anomaly_rate
    
    print(f"âœ… Anomaly detection completed")
    print(f"   - Total anomalies found: {total_anomalies}")
    print(f"   - Anomaly rate: {anomaly_rate:.2%}")
    
    return state

async def generate_quality_rules(state: Dict[str, Any]) -> Dict[str, Any]:
    """Generate data quality rules based on identified anomalies."""
    print("ğŸ“‹ Generating quality rules...")
    await asyncio.sleep(1)
    
    anomalies = state['anomalies']
    rules = []
    
    # Generate rules based on anomaly patterns
    if anomalies['null_values']:
        rules.append({
            'rule_id': 'null_value_cleanup',
            'description': 'Remove or impute null values',
            'action': 'remove_nulls',
            'priority': 'high',
            'affected_records': len(anomalies['null_values'])
        })
    
    if anomalies['invalid_emails']:
        rules.append({
            'rule_id': 'email_format_fix',
            'description': 'Fix or remove invalid email formats',
            'action': 'fix_emails',
            'priority': 'high',
            'affected_records': len(anomalies['invalid_emails'])
        })
    
    if anomalies['age_outliers']:
        rules.append({
            'rule_id': 'age_outlier_correction',
            'description': 'Correct unrealistic age values',
            'action': 'fix_age_outliers',
            'priority': 'medium',
            'affected_records': len(anomalies['age_outliers'])
        })
    
    if anomalies['salary_outliers']:
        rules.append({
            'rule_id': 'salary_outlier_correction',
            'description': 'Correct unrealistic salary values',
            'action': 'fix_salary_outliers',
            'priority': 'medium',
            'affected_records': len(anomalies['salary_outliers'])
        })
    
    if anomalies['department_inconsistencies']:
        rules.append({
            'rule_id': 'department_standardization',
            'description': 'Standardize department names',
            'action': 'standardize_departments',
            'priority': 'low',
            'affected_records': len(anomalies['department_inconsistencies'])
        })
    
    if anomalies['future_dates']:
        rules.append({
            'rule_id': 'future_date_correction',
            'description': 'Correct future join dates',
            'action': 'fix_future_dates',
            'priority': 'high',
            'affected_records': len(anomalies['future_dates'])
        })
    
    if anomalies['score_outliers']:
        rules.append({
            'rule_id': 'score_range_correction',
            'description': 'Correct scores outside valid range',
            'action': 'fix_score_outliers',
            'priority': 'medium',
            'affected_records': len(anomalies['score_outliers'])
        })
    
    state['quality_rules'] = rules
    
    print(f"âœ… Generated {len(rules)} quality rules")
    for rule in rules:
        print(f"   - {rule['description']} (Priority: {rule['priority']}, Affects: {rule['affected_records']} records)")
    
    return state

async def apply_quality_rules(state: Dict[str, Any]) -> Dict[str, Any]:
    """Apply the generated quality rules to clean the data."""
    print("ğŸ”§ Applying quality rules...")
    await asyncio.sleep(2)
    
    dataset = state['dataset']
    rules = state['quality_rules']
    anomalies = state['anomalies']
    
    cleaned_dataset = []
    fixes_applied = {
        'records_removed': 0,
        'values_corrected': 0,
        'values_standardized': 0
    }
    
    # Create a set of record IDs to remove
    records_to_remove = set()
    
    # Collect records with critical issues for removal
    for anomaly in anomalies['null_values']:
        if anomaly['field'] in ['name', 'email']:  # Critical fields
            records_to_remove.add(anomaly['record_id'])
    
    for anomaly in anomalies['invalid_emails']:
        records_to_remove.add(anomaly['record_id'])
    
    # Process each record
    for record in dataset:
        record_id = record.get('id')
        
        # Skip records marked for removal
        if record_id in records_to_remove:
            fixes_applied['records_removed'] += 1
            continue
        
        # Create a copy of the record for modification
        cleaned_record = record.copy()
        
        # Apply age corrections
        age = cleaned_record.get('age')
        if isinstance(age, (int, float)) and (age < 18 or age > 70):
            cleaned_record['age'] = max(18, min(70, age))  # Clamp to valid range
            fixes_applied['values_corrected'] += 1
        
        # Apply salary corrections
        salary = cleaned_record.get('salary')
        if isinstance(salary, (int, float)) and (salary < 20000 or salary > 500000):
            cleaned_record['salary'] = max(20000, min(500000, salary))  # Clamp to valid range
            fixes_applied['values_corrected'] += 1
        
        # Apply score corrections
        score = cleaned_record.get('score')
        if isinstance(score, (int, float)) and (score < 0 or score > 100):
            cleaned_record['score'] = max(0, min(100, score))  # Clamp to valid range
            fixes_applied['values_corrected'] += 1
        
        # Standardize department names
        department = cleaned_record.get('department')
        if department:
            dept_mapping = {
                'Eng': 'Engineering',
                'engineering': 'Engineering',
                'SALES': 'Sales',
                'mktg': 'Marketing'
            }
            if department in dept_mapping:
                cleaned_record['department'] = dept_mapping[department]
                fixes_applied['values_standardized'] += 1
        
        # Fix future dates
        join_date = cleaned_record.get('join_date')
        if join_date:
            try:
                date_obj = datetime.fromisoformat(join_date.replace('Z', '+00:00'))
                if date_obj > datetime.now():
                    # Set to current date
                    cleaned_record['join_date'] = datetime.now().isoformat()
                    fixes_applied['values_corrected'] += 1
            except:
                pass
        
        cleaned_dataset.append(cleaned_record)
    
    # Update state with cleaned dataset
    state['dataset'] = cleaned_dataset
    state['fixes_applied'] = fixes_applied
    
    print(f"âœ… Quality rules applied")
    print(f"   - Records removed: {fixes_applied['records_removed']}")
    print(f"   - Values corrected: {fixes_applied['values_corrected']}")
    print(f"   - Values standardized: {fixes_applied['values_standardized']}")
    print(f"   - Dataset size after cleaning: {len(cleaned_dataset)}")
    
    return state

def evaluate_quality_improvement(state: Dict[str, Any]) -> Dict[str, Any]:
    """Evaluate the quality improvement and determine next action."""
    print("ğŸ“ˆ Evaluating quality improvement...")
    time.sleep(0.5)
    
    current_anomaly_rate = state.get('anomaly_rate', 0)
    target_rate = state['target_anomaly_rate']
    iteration = state['iteration']
    max_iterations = state['max_iterations']
    
    # Record quality metrics for this iteration
    quality_metrics = {
        'iteration': iteration,
        'anomaly_rate': current_anomaly_rate,
        'total_anomalies': state.get('total_anomalies', 0),
        'dataset_size': len(state['dataset']),
        'fixes_applied': state.get('fixes_applied', {}),
        'timestamp': datetime.now().isoformat()
    }
    
    state['quality_history'].append(quality_metrics)
    
    # Calculate improvement
    if len(state['quality_history']) > 1:
        previous_rate = state['quality_history'][-2]['anomaly_rate']
        improvement = previous_rate - current_anomaly_rate
        state['quality_improvement'] = improvement
        print(f"   - Quality improvement: {improvement:.2%}")
    
    print(f"   - Current anomaly rate: {current_anomaly_rate:.2%}")
    print(f"   - Target anomaly rate: {target_rate:.2%}")
    print(f"   - Iteration: {iteration}/{max_iterations}")
    
    # Determine if we should continue the quality loop
    should_continue = current_anomaly_rate > target_rate and iteration < max_iterations
    
    if should_continue:
        print(f"ğŸ”„ Quality loop continuing (Rate: {current_anomaly_rate:.2%} > Target: {target_rate:.2%})")
        state['continue_loop'] = True
        
        # For demo purposes, simulate one more iteration in sync mode
        if iteration == 1:  # Only do one additional iteration
            temp_state = copy.deepcopy(state)
            temp_state['iteration'] += 1
            
            # Simulate another round of improvements
            temp_state['anomaly_rate'] = max(0.05, current_anomaly_rate * 0.7)  # 30% improvement
            temp_state['total_anomalies'] = int(temp_state['anomaly_rate'] * len(temp_state['dataset']))
            
            quality_metrics_2 = {
                'iteration': temp_state['iteration'],
                'anomaly_rate': temp_state['anomaly_rate'],
                'total_anomalies': temp_state['total_anomalies'],
                'dataset_size': len(temp_state['dataset']),
                'fixes_applied': {'records_removed': 10, 'values_corrected': 15, 'values_standardized': 5},
                'timestamp': datetime.now().isoformat()
            }
            temp_state['quality_history'].append(quality_metrics_2)
            
            # Check if we've reached target now
            if temp_state['anomaly_rate'] <= target_rate:
                print(f"âœ… Target achieved after iteration {temp_state['iteration']}")
                temp_state['continue_loop'] = False
                return temp_state
            else:
                print(f"ğŸ”„ Still above target after iteration {temp_state['iteration']}")
                temp_state['continue_loop'] = False  # Stop for demo
                return temp_state
    else:
        reason = "target achieved" if current_anomaly_rate <= target_rate else "max iterations reached"
        print(f"âœ… Quality loop completed ({reason})")
        state['continue_loop'] = False
    
    return state

async def finalize_quality_report(state: Dict[str, Any]) -> Dict[str, Any]:
    """Generate final quality report and summary."""
    print("ğŸ“Š Generating final quality report...")
    await asyncio.sleep(1)
    
    history = state['quality_history']
    original_size = state['original_size']
    final_size = len(state['dataset'])
    
    # Calculate overall improvement
    initial_rate = history[0]['anomaly_rate'] if history else 0
    final_rate = history[-1]['anomaly_rate'] if history else 0
    total_improvement = initial_rate - final_rate
    
    # Generate comprehensive report
    quality_report = {
        'pipeline_summary': {
            'start_time': state['pipeline_start_time'],
            'end_time': datetime.now().isoformat(),
            'total_iterations': len(history),
            'original_dataset_size': original_size,
            'final_dataset_size': final_size,
            'records_removed': original_size - final_size
        },
        'quality_metrics': {
            'initial_anomaly_rate': initial_rate,
            'final_anomaly_rate': final_rate,
            'total_improvement': total_improvement,
            'target_achieved': final_rate <= state['target_anomaly_rate']
        },
        'iteration_history': history,
        'final_dataset_sample': state['dataset'][:5] if state['dataset'] else []
    }
    
    state['quality_report'] = quality_report
    state['pipeline_completed'] = True
    
    print(f"âœ… Data Quality Pipeline completed!")
    print(f"   - Total iterations: {len(history)}")
    print(f"   - Quality improvement: {total_improvement:.2%}")
    print(f"   - Final anomaly rate: {final_rate:.2%}")
    print(f"   - Target achieved: {quality_report['quality_metrics']['target_achieved']}")
    print(f"   - Records processed: {original_size} â†’ {final_size}")
    
    return state

# ============================================================================
# Data Quality Pipeline Node Registry
# ============================================================================

DATA_QUALITY_NODES = {
    'initialize_dataset': initialize_dataset,
    'profile_data': profile_data,
    'identify_anomalies': identify_anomalies,
    'generate_quality_rules': generate_quality_rules,
    'apply_quality_rules': apply_quality_rules,
    'evaluate_quality_improvement': evaluate_quality_improvement,
    'finalize_quality_report': finalize_quality_report,
}

# ============================================================================
# Workflow Demonstration Functions
# ============================================================================

async def create_data_quality_workflow():
    """Create the Data Quality Pipeline workflow graph."""
    print("ğŸ”§ Creating Data Quality Pipeline workflow...")
    
    base_url = "http://localhost:8000"
    
    workflow_definition = {
        "nodes": [
            "initialize_dataset",
            "profile_data", 
            "identify_anomalies",
            "generate_quality_rules",
            "apply_quality_rules",
            "evaluate_quality_improvement",
            "finalize_quality_report"
        ],
        "edges": [
            {"from_node": "initialize_dataset", "to_node": "profile_data"},
            {"from_node": "profile_data", "to_node": "identify_anomalies"},
            {"from_node": "identify_anomalies", "to_node": "generate_quality_rules"},
            {"from_node": "generate_quality_rules", "to_node": "apply_quality_rules"},
            {"from_node": "apply_quality_rules", "to_node": "evaluate_quality_improvement"},
            {"from_node": "evaluate_quality_improvement", "to_node": "finalize_quality_report"}
        ],
        "start_node": "initialize_dataset"
    }
    
    async with aiohttp.ClientSession() as session:
        async with session.post(f"{base_url}/graph/create", json=workflow_definition) as resp:
            if resp.status == 200:
                result = await resp.json()
                graph_id = result["graph_id"]
                print(f"âœ… Data Quality Pipeline created: {graph_id}")
                return graph_id
            else:
                error_text = await resp.text()
                print(f"âŒ Failed to create workflow: {resp.status} - {error_text}")
                return None

async def run_pipeline_demo(graph_id: str):
    """Run comprehensive pipeline demonstrations."""
    print("\nğŸš€ Running Data Quality Pipeline Demonstrations...")
    
    base_url = "http://localhost:8000"
    
    # Test scenarios showcasing different aspects
    test_scenarios = [
        {
            "name": "Small Dataset - Quick Processing",
            "params": {
                "dataset_size": 300,
                "max_iterations": 3,
                "target_anomaly_rate": 0.12,
                "pipeline_name": "Small Dataset Quality Check"
            }
        },
        {
            "name": "Medium Dataset - Moderate Target",
            "params": {
                "dataset_size": 600,
                "max_iterations": 4,
                "target_anomaly_rate": 0.08,
                "pipeline_name": "Medium Dataset Processing"
            }
        },
        {
            "name": "Large Dataset - Aggressive Target",
            "params": {
                "dataset_size": 1000,
                "max_iterations": 5,
                "target_anomaly_rate": 0.05,
                "pipeline_name": "Large Dataset Comprehensive Cleaning"
            }
        }
    ]
    
    async with aiohttp.ClientSession() as session:
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"\nğŸ“Š Test Scenario {i}: {scenario['name']}")
            await run_async_execution(session, base_url, graph_id, scenario['params'])
            
            if i < len(test_scenarios):
                print("   â³ Waiting before next scenario...")
                await asyncio.sleep(2)

async def run_async_execution(session, base_url: str, graph_id: str, params: dict):
    """Run an async pipeline execution and monitor progress."""
    
    print(f"   ğŸ“‹ Parameters:")
    print(f"      - Dataset size: {params['dataset_size']} records")
    print(f"      - Target anomaly rate: {params['target_anomaly_rate']:.1%}")
    print(f"      - Max iterations: {params['max_iterations']}")
    
    # Start async execution
    run_request = {
        "graph_id": graph_id,
        "initial_state": params
    }
    
    async with session.post(f"{base_url}/graph/run/async", json=run_request) as resp:
        if resp.status == 200:
            result = await resp.json()
            execution_id = result["execution_id"]
            print(f"   ğŸš€ Execution started: {execution_id[:8]}...")
        else:
            print(f"   âŒ Failed to start execution: {resp.status}")
            return
    
    # Monitor progress
    print(f"   ğŸ“Š Monitoring progress...")
    step_count = 0
    
    while True:
        async with session.get(f"{base_url}/execution/{execution_id}") as resp:
            if resp.status == 200:
                execution = await resp.json()
                status = execution["status"]
                current_node = execution.get("current_node", "N/A")
                progress = execution.get("progress", 0)
                
                if progress > step_count:
                    print(f"      â†’ Step {progress}: {current_node}")
                    step_count = progress
                
                if status in ["completed", "failed", "cancelled"]:
                    break
            
            await asyncio.sleep(1)
    
    # Display results
    if execution["status"] == "completed":
        print(f"   âœ… Execution completed successfully!")
        
        final_state = execution.get("final_state", {})
        if 'quality_report' in final_state:
            report = final_state['quality_report']
            metrics = report['quality_metrics']
            summary = report['pipeline_summary']
            
            print(f"   ğŸ“ˆ Quality Results:")
            print(f"      - Initial anomaly rate: {metrics['initial_anomaly_rate']:.2%}")
            print(f"      - Final anomaly rate: {metrics['final_anomaly_rate']:.2%}")
            print(f"      - Quality improvement: {metrics['total_improvement']:.2%}")
            print(f"      - Target achieved: {'âœ… Yes' if metrics['target_achieved'] else 'âŒ No'}")
            print(f"      - Total iterations: {summary['total_iterations']}")
            print(f"      - Records processed: {summary['original_dataset_size']} â†’ {summary['final_dataset_size']}")
            
            # Show iteration history if multiple iterations
            if len(report['iteration_history']) > 1:
                print(f"   ğŸ”„ Iteration History:")
                for hist in report['iteration_history']:
                    print(f"      - Iteration {hist['iteration']}: {hist['anomaly_rate']:.2%} anomalies")
        else:
            print(f"   âš ï¸  Completed but no quality report available")
    else:
        print(f"   âŒ Execution {execution['status']}: {execution.get('error', 'Unknown error')}")

def show_capabilities():
    """Display the comprehensive capabilities demonstrated."""
    print("ğŸ¯ Workflow Engine Capabilities Demonstrated")
    print("=" * 50)
    
    capabilities = [
        ("ğŸ”„ Async Node Execution", "Long-running data processing operations"),
        ("ğŸ“Š Sequential Processing", "Ordered execution through pipeline stages"),
        ("ğŸ’¾ State Management", "Progressive data transformation and tracking"),
        ("ğŸ”€ Conditional Logic", "Quality-based decision making"),
        ("ğŸ” Iterative Processing", "Looping until quality targets are met"),
        ("ğŸ“¡ Real-time Monitoring", "Live progress tracking via REST API"),
        ("âš¡ Concurrent Execution", "Multiple pipelines running simultaneously"),
        ("ğŸ›¡ï¸ Error Handling", "Graceful failure management and recovery"),
        ("ğŸ’½ Persistent Storage", "Graph definitions stored in SQLite"),
        ("ğŸ“‹ Comprehensive Reporting", "Detailed quality metrics and history")
    ]
    
    for icon_title, description in capabilities:
        print(f"   {icon_title}: {description}")
    
    print(f"\nğŸ”¬ Data Quality Pipeline Stages:")
    stages = [
        ("ğŸ“Š Data Profiling", "Statistical analysis and completeness metrics"),
        ("ğŸ” Anomaly Detection", "Identification of data quality issues"),
        ("ğŸ“‹ Rule Generation", "Automatic creation of data cleaning rules"),
        ("ğŸ”§ Rule Application", "Execution of data transformation and cleaning"),
        ("ğŸ“ˆ Quality Evaluation", "Progress tracking and improvement measurement"),
        ("ğŸ”„ Iterative Improvement", "Looping until quality targets are achieved"),
        ("ğŸ“Š Final Reporting", "Comprehensive quality assessment and summary")
    ]
    
    for stage_title, description in stages:
        print(f"   {stage_title}: {description}")

async def main():
    """Main demonstration function."""
    print("ğŸš€ Complete Data Quality Pipeline Demonstration")
    print("=" * 60)
    print("This demonstration showcases a real-world data quality pipeline")
    print("that processes datasets through iterative quality improvement.")
    print()
    print("Pipeline Stages:")
    print("1. Profile data - Analyze data characteristics and statistics")
    print("2. Identify anomalies - Detect data quality issues and outliers")
    print("3. Generate rules - Create data quality rules based on findings")
    print("4. Apply rules - Execute data cleaning and validation rules")
    print("5. Loop until anomaly count is acceptable - Iterative improvement")
    print()
    print("Make sure the FastAPI server is running on http://localhost:8000")
    print("with the data quality nodes registered in NODE_REGISTRY")
    print()
    
    show_capabilities()
    
    # Create and run the workflow
    graph_id = await create_data_quality_workflow()
    if graph_id:
        await run_pipeline_demo(graph_id)
        
        print(f"\nğŸ‰ Data Quality Pipeline demonstration completed!")
        print(f"The workflow engine successfully demonstrated:")
        print(f"âœ… Complex real-world data processing scenarios")
        print(f"âœ… Async execution with progress monitoring")
        print(f"âœ… Iterative improvement through quality loops")
        print(f"âœ… Comprehensive state management and reporting")
        print(f"âœ… Scalable processing across different dataset sizes")

if __name__ == "__main__":
    print("=" * 60)
    print("COMPLETE DATA QUALITY PIPELINE DEMONSTRATION")
    print("=" * 60)
    print()
    print("This single file contains everything needed to demonstrate")
    print("the workflow engine's capabilities through a comprehensive")
    print("data quality pipeline with iterative improvement.")
    print()
    
    asyncio.run(main())